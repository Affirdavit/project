{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mrWa1Bg0QDbc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tarfile\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "\n",
        "# Step 1: Download the dataset\n",
        "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "filename = \"aclImdb_v1.tar.gz\"\n",
        "urllib.request.urlretrieve(url, filename)\n",
        "\n",
        "# Step 2: Extract the tar.gz file\n",
        "with tarfile.open(filename, \"r:gz\") as tar:\n",
        "    tar.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5UswfziTkgQ",
        "outputId": "e4eee66a-2811-44b6-e547-773da45e1f6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: No valid output stream.\n"
          ]
        }
      ],
      "source": [
        "import pyprind\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# change the 'basepath' to the directory of the\n",
        "# unzipped movie dataset\n",
        "\n",
        "basepath = 'aclImdb'\n",
        "\n",
        "labels = {'pos': 1, 'neg': 0}\n",
        "pbar = pyprind.ProgBar(50000)\n",
        "data_list = [] # Use a list to store data before creating the DataFrame\n",
        "\n",
        "for s in ('test', 'train'):\n",
        "  for l in ('pos', 'neg'):\n",
        "    path = os.path.join(basepath, s, l)\n",
        "    for file in sorted(os.listdir(path)):\n",
        "      with open(os.path.join(path, file), 'r', encoding='utf-8') as infile:\n",
        "        txt = infile.read()\n",
        "      data_list.append([txt, labels[l]]) # Append to the list\n",
        "      pbar.update()\n",
        "\n",
        "df = pd.DataFrame(data_list, columns=['review', 'sentiment']) # Create DataFrame from the list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XDdhKaDFUwDo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "df = df.reindex(np.random.permutation(df.index))\n",
        "df.to_csv('movie_data.csv', index=False, encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZztjepIKVA7z",
        "outputId": "e89a096c-ae59-4062-e320-9d1440739b2a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hi for all the people who have seen this wonde...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I recently bought the DVD, forgetting just how...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
              "1  OK... so... I really like Kris Kristofferson a...          0\n",
              "2  ***SPOILER*** Do not read this, if you think a...          0\n",
              "3  hi for all the people who have seen this wonde...          1\n",
              "4  I recently bought the DVD, forgetting just how...          0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('movie_data.csv', encoding='utf-8')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-B8PrKmp8JY",
        "outputId": "37069126-061f-484b-95db-36d6b130eee1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "n_XOUxk5qBF_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count = CountVectorizer()\n",
        "docs = np.array(['The sun is shining',\n",
        "                 'The weather is sweet',\n",
        "                 'The sun is shining, the weather is sweet',\n",
        "                 'and one and one is two'])\n",
        "bag = count.fit_transform(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSU5rMHszoh4",
        "outputId": "97e63cdf-6af0-4356-f4c9-8f274c6104bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'the': 6,\n",
              " 'sun': 4,\n",
              " 'is': 1,\n",
              " 'shining': 3,\n",
              " 'weather': 8,\n",
              " 'sweet': 5,\n",
              " 'and': 0,\n",
              " 'one': 2,\n",
              " 'two': 7}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMX2WRVnzvJT",
        "outputId": "cb22934f-d78f-4a77-d0d6-67bb92044f76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 1, 1, 0, 1, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 1, 1, 0, 1],\n",
              "       [0, 2, 0, 1, 1, 1, 2, 0, 1],\n",
              "       [2, 1, 2, 0, 0, 0, 0, 1, 0]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bag.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITkLwKUEz2f1",
        "outputId": "15079483-974f-496c-dda8-283f0a7f54ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.   0.38 0.   0.57 0.57 0.   0.46 0.   0.  ]\n",
            " [0.   0.38 0.   0.   0.   0.57 0.46 0.   0.57]\n",
            " [0.   0.46 0.   0.35 0.35 0.35 0.56 0.   0.35]\n",
            " [0.66 0.17 0.66 0.   0.   0.   0.   0.33 0.  ]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf = TfidfTransformer(use_idf=True, norm='l2', smooth_idf=True)\n",
        "np.set_printoptions(precision=2)\n",
        "print(tfidf.fit_transform(count.fit_transform(docs)).toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "130lU5W21qkC",
        "outputId": "a75587cd-7563-4b69-b40b-19b05efa5b91"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'is seven.<br /><br />Title (Brazil): Not Available'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.loc[0, 'review'][-50:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "K4c0qUkU3gsg"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def preprocessor(text):\n",
        "  text = re.sub('<[^>]*>', '', text)\n",
        "  emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
        "  text = (re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', ''))\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "NywYczIZ49nm",
        "outputId": "518205d1-438a-4e8f-96ae-e8ab2b2308a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'is seven title brazil not available'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocessor(df.loc[0, 'review'][-50:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8rLQxROGPC8L",
        "outputId": "fce6847c-9233-4921-d46a-986a81666ca7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'this is a test :) :( :)'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocessor(\"</a>This :) is :( a test :-)!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pQek_z6OPIdQ",
        "outputId": "eda99923-4810-4774-ff59-c17ef953d1f6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>in 1974 the teenager martha moxley maggie grac...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ok so i really like kris kristofferson and his...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spoiler do not read this if you think about w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hi for all the people who have seen this wonde...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i recently bought the dvd forgetting just how ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  in 1974 the teenager martha moxley maggie grac...          1\n",
              "1  ok so i really like kris kristofferson and his...          0\n",
              "2   spoiler do not read this if you think about w...          0\n",
              "3  hi for all the people who have seen this wonde...          1\n",
              "4  i recently bought the dvd forgetting just how ...          0"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['review'] = df['review'].apply(preprocessor)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORiOaBj0POFY",
        "outputId": "040b50f2-85e4-4f5c-bd18-a96c21dd1df5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['runners', 'like', 'running', 'and', 'thus', 'they', 'run']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def tokenizer(text):\n",
        "  return text.split()\n",
        "tokenizer('runners like running and thus they run')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwhwlTogPlug"
      },
      "source": [
        "stemming is the process of transforming a word into its roof form."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEWVU6Y0Pym6",
        "outputId": "2f2fb920-6f22-4c5e-9ab2-e002e60b2044"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['runner', 'like', 'run', 'and', 'thu', 'they', 'run']"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "porter = PorterStemmer()\n",
        "def tokenizer_porter(text):\n",
        "  return [porter.stem(word) for word in text.split()]\n",
        "\n",
        "tokenizer_porter('runners like running and thus they run')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDsmJIuSQFJz",
        "outputId": "cda95301-c105-4cb3-a652-a04826c0fdbe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/tieulyphidao/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43zL_YMzQkY-",
        "outputId": "5d74ceeb-904c-499c-9748-8b2efa85f2c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['runner', 'like', 'run', 'run', 'lot']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop = stopwords.words('english')\n",
        "[w for w in tokenizer_porter('a runner likes running and runs a lot')[-10:]\n",
        " if w not in stop]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "7Nkry3RLQ2Zx"
      },
      "outputs": [],
      "source": [
        "X_train = df.loc[:25000, 'review'].values\n",
        "y_train = df.loc[:25000, 'sentiment'].values\n",
        "X_test = df.loc[25000:, 'review'].values\n",
        "y_test = df.loc[25000:, 'sentiment'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "DpFbcM9lRLly",
        "outputId": "2ffda1cb-bd3b-4dce-9f3f-2158848b5e97"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\n\\ntfidf = TfidfVectorizer(strip_accents=None, lowercase=False, preprocessor=None)\\nparam_grid = [\\n    {'vect__ngram_range': [(1, 1)],\\n     'vect__stop_words': [stop, None],\\n     'vect__tokenizer': [tokenizer, tokenizer_porter],\\n     'clf__penalty': ['l1', 'l2'],\\n     'clf__C': [1.0, 10.0, 100.0]},\\n    {'vect__ngram_range': [(1, 1)],\\n     'vect__stop_words': [stop, None],\\n     'vect__tokenizer': [tokenizer, tokenizer_porter],\\n     'vect__use_idf': [False],\\n     'vect__norm': [None],\\n     'clf__penalty': ['l1', 'l2'],\\n     'clf__C': [1.0, 10.0, 100.0]}\\n]\\n\\nlr_tfidf = Pipeline(\\n    steps=[\\n        ('vect', tfidf),\\n        ('clf', LogisticRegression(random_state=0, solver='liblinear'))\\n    ]\\n)\\n\\ngs_lr_tfidf = GridSearchCV(estimator=lr_tfidf, param_grid=param_grid,\\n                           scoring='accuracy', cv=5, verbose=2,\\n                           n_jobs=-1)\\n\\ngs_lr_tfidf.fit(X_train, y_train)\\n\""
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This run would take more than 1 hour in colab\n",
        "# Local run is advisable\n",
        "\"\"\"\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(strip_accents=None, lowercase=False, preprocessor=None)\n",
        "param_grid = [\n",
        "    {'vect__ngram_range': [(1, 1)],\n",
        "     'vect__stop_words': [stop, None],\n",
        "     'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
        "     'clf__penalty': ['l1', 'l2'],\n",
        "     'clf__C': [1.0, 10.0, 100.0]},\n",
        "    {'vect__ngram_range': [(1, 1)],\n",
        "     'vect__stop_words': [stop, None],\n",
        "     'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
        "     'vect__use_idf': [False],\n",
        "     'vect__norm': [None],\n",
        "     'clf__penalty': ['l1', 'l2'],\n",
        "     'clf__C': [1.0, 10.0, 100.0]}\n",
        "]\n",
        "\n",
        "lr_tfidf = Pipeline(\n",
        "    steps=[\n",
        "        ('vect', tfidf),\n",
        "        ('clf', LogisticRegression(random_state=0, solver='liblinear'))\n",
        "    ]\n",
        ")\n",
        "\n",
        "gs_lr_tfidf = GridSearchCV(estimator=lr_tfidf, param_grid=param_grid,\n",
        "                           scoring='accuracy', cv=5, verbose=2,\n",
        "                           n_jobs=-1)\n",
        "\n",
        "gs_lr_tfidf.fit(X_train, y_train)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmYhDaCjWQN9"
      },
      "outputs": [],
      "source": [
        "print('Best parameter set: %s ' % gs_lr_tfidf.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gv6ppSmvWYBN"
      },
      "outputs": [],
      "source": [
        "print('CV accuracy: %.3f' % gs_lr_tfidf.best_score_)\n",
        "clf = gs_lr_tfidf.best_estimator_\n",
        "print('Test Accuracy: %.3f' % clf.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_Bu4J_9NSkqM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "def tokenizer(text):\n",
        "  text = re.sub('<[^>]*>', '', text)\n",
        "  emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
        "  text = re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', '')\n",
        "  tokenized = [w for w in text.split() if w not in stop]\n",
        "  return tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "kEoZtSgTWNdI"
      },
      "outputs": [],
      "source": [
        "def stream_docs(path):\n",
        "  with open(path, 'r', encoding='utf-8') as csv:\n",
        "    next(csv) # skip header\n",
        "    for line in csv:\n",
        "      text, label = line[:-3], int(line[-2])\n",
        "      yield text, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pneyuo40XBow",
        "outputId": "cb5c64ea-2ffb-4899-c223-284af26be82f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('\"In 1974, the teenager Martha Moxley (Maggie Grace) moves to the high-class area of Belle Haven, Greenwich, Connecticut. On the Mischief Night, eve of Halloween, she was murdered in the backyard of her house and her murder remained unsolved. Twenty-two years later, the writer Mark Fuhrman (Christopher Meloni), who is a former LA detective that has fallen in disgrace for perjury in O.J. Simpson trial and moved to Idaho, decides to investigate the case with his partner Stephen Weeks (Andrew Mitchell) with the purpose of writing a book. The locals squirm and do not welcome them, but with the support of the retired detective Steve Carroll (Robert Forster) that was in charge of the investigation in the 70\\'s, they discover the criminal and a net of power and money to cover the murder.<br /><br />\"\"Murder in Greenwich\"\" is a good TV movie, with the true story of a murder of a fifteen years old girl that was committed by a wealthy teenager whose mother was a Kennedy. The powerful and rich family used their influence to cover the murder for more than twenty years. However, a snoopy detective and convicted perjurer in disgrace was able to disclose how the hideous crime was committed. The screenplay shows the investigation of Mark and the last days of Martha in parallel, but there is a lack of the emotion in the dramatization. My vote is seven.<br /><br />Title (Brazil): Not Available\"',\n",
              " 1)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(stream_docs(path='movie_data.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "iZ8tTyeiXQNA"
      },
      "outputs": [],
      "source": [
        "def get_minibatch(doc_stream, size):\n",
        "  docs, y = [], []\n",
        "  try:\n",
        "    for _ in range(size):\n",
        "      text, label = next(doc_stream)\n",
        "      docs.append(text)\n",
        "      y.append(label)\n",
        "  except StopIteration:\n",
        "    return None, None\n",
        "  return docs, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-vxXGU-aXi2w"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "vect = HashingVectorizer(decode_error='ignore', n_features=2**21,\n",
        "                         preprocessor=None, tokenizer=tokenizer)\n",
        "clf = SGDClassifier(loss='log_loss', random_state=1)\n",
        "doc_stream = stream_docs(path='movie_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPhuZ1vBZF_s",
        "outputId": "f3448633-3ebe-4699-c765-c693863b881f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: No valid output stream.\n"
          ]
        }
      ],
      "source": [
        "import pyprind\n",
        "pbar = pyprind.ProgBar(45)\n",
        "classes = np.array([0, 1])\n",
        "\n",
        "for _ in range(45):\n",
        "  X_train, y_train = get_minibatch(doc_stream=doc_stream, size=1000)\n",
        "  if not X_train:\n",
        "    break\n",
        "  X_train = vect.transform(X_train)\n",
        "  clf.partial_fit(X_train, y_train, classes=classes)\n",
        "  pbar.update()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UhTbzEkaUUD",
        "outputId": "463bf106-292b-446d-bf8b-80ab2e98ba52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.868\n"
          ]
        }
      ],
      "source": [
        "X_test, y_test = get_minibatch(doc_stream, size=5000)\n",
        "X_test = vect.transform(X_test)\n",
        "print('Accuracy: %.3f' % clf.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "U7_SYPtZasnM"
      },
      "outputs": [],
      "source": [
        "clf = clf.partial_fit(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "6HmcSbfPfP-W"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('movie_data.csv', encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "2vesB8NefUeG"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count = CountVectorizer(stop_words='english', max_df=.1, max_features=5000)\n",
        "X = count.fit_transform(df['review'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "dX_E1GRjgvtk"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "lda = LatentDirichletAllocation(n_components=10, random_state=123, learning_method='batch')\n",
        "X_topics = lda.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYKg0wsUhP9t",
        "outputId": "c95f6084-7ee5-4798-edd1-734ef0ec65f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10, 5000)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lda.components_.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_9-aTljhSRo",
        "outputId": "b000cc70-16da-4be4-bac1-7e2534885a77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Topic 1:\n",
            "worst minutes awful script stupid\n",
            "Topic 2:\n",
            "family mother father children girl\n",
            "Topic 3:\n",
            "american war dvd music tv\n",
            "Topic 4:\n",
            "human audience cinema art sense\n",
            "Topic 5:\n",
            "police guy car dead murder\n",
            "Topic 6:\n",
            "horror house sex girl woman\n",
            "Topic 7:\n",
            "role performance comedy actor performances\n",
            "Topic 8:\n",
            "series episode war episodes tv\n",
            "Topic 9:\n",
            "book version original read novel\n",
            "Topic 10:\n",
            "action fight guy guys cool\n"
          ]
        }
      ],
      "source": [
        "n_top_words = 5\n",
        "feature_names = count.get_feature_names_out()\n",
        "for topic_idx, topic in enumerate(lda.components_):\n",
        "  print(\"Topic %d:\" % (topic_idx + 1))\n",
        "  print(\" \".join([feature_names[i]\n",
        "                  for i in topic.argsort()\\\n",
        "                  [:-n_top_words - 1:-1]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UM5dwddIh6VD",
        "outputId": "dca08cea-a249-4f90-cf52-b7073f2d690c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Horror movie #1:\n",
            "House of Dracula works from the same basic premise as House of Frankenstein from the year before; namely that Universal's three most famous monsters; Dracula, Frankenstein's Monster and The Wolf Man are appearing in the movie together. Naturally, the film is rather messy therefore, but the fact that ...\n",
            "\n",
            "Horror movie #2:\n",
            "Okay, what the hell kind of TRASH have I been watching now? \"The Witches' Mountain\" has got to be one of the most incoherent and insane Spanish exploitation flicks ever and yet, at the same time, it's also strangely compelling. There's absolutely nothing that makes sense here and I even doubt there  ...\n",
            "\n",
            "Horror movie #3:\n",
            "<br /><br />Horror movie time, Japanese style. Uzumaki/Spiral was a total freakfest from start to finish. A fun freakfest at that, but at times it was a tad too reliant on kitsch rather than the horror. The story is difficult to summarize succinctly: a carefree, normal teenage girl starts coming fac ...\n"
          ]
        }
      ],
      "source": [
        "horror = X_topics[:, 5].argsort()[::-1]\n",
        "\n",
        "for iter_idx, movie_idx in enumerate(horror[:3]):\n",
        "  print('\\nHorror movie #%d:' % (iter_idx + 1))\n",
        "  print(df['review'][movie_idx][:300], '...')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "sfuIMAcioOdj"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "dest = os.path.join('movieclassifier', 'pkl_objects')\n",
        "if not os.path.exists(dest):\n",
        "  os.makedirs(dest)\n",
        "pickle.dump(stop, open(os.path.join(dest, 'stopwords.pkl'), 'wb'),\n",
        "            protocol=4)\n",
        "pickle.dump(clf, open(os.path.join(dest, 'classifier.pkl'), 'wb'),\n",
        "            protocol=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "JzfuptCDpADh"
      },
      "outputs": [],
      "source": [
        "code = '''\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "import re\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "cur_dir = os.path.dirname(__file__)\n",
        "stop = pickle.load(open(os.path.join(cur_dir, 'pkl_objects', 'stopwords.pkl'), 'rb'))\n",
        "\n",
        "def tokenizer(text):\n",
        "  text = re.sub('<[^>]*>', '', text)\n",
        "  emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
        "  text = re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', '')\n",
        "  tokenized = [w for w in text.split() if w not in stop]\n",
        "  return tokenized\n",
        "\n",
        "vect = HashingVectorizer(decode_error='ignore', n_features=2**21,\n",
        "                         preprocessor=None, tokenizer=tokenizer)\n",
        "'''\n",
        "with open(os.path.join(os.getcwd(), 'movieclassifier', 'vectorizer.py'), 'w') as f:\n",
        "  f.write(code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "dBaEMXy_smPz"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Add the directory containing the vectorizer.py file to the system path\n",
        "sys.path.append(os.path.join(os.getcwd(), 'movieclassifier'))\n",
        "\n",
        "from vectorizer import vect\n",
        "clf = pickle.load(open(os.path.join(os.getcwd(), 'movieclassifier',\n",
        "                                    'pkl_objects', 'classifier.pkl'), 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_QWCxmztVj0",
        "outputId": "c778a3f5-0ed6-4d0a-8188-3bef8be81cd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction: positive\n",
            "Probability: 95.55%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "label = {0: 'negative', 1: 'positive'}\n",
        "\n",
        "example = [\"I love this movie. It's amazing.\"]\n",
        "X = vect.transform(example)\n",
        "print('Prediction: %s\\nProbability: %.2f%%'\\\n",
        "      % (label[clf.predict(X)[0]],\n",
        "         np.max(clf.predict_proba(X))*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onbZtC7nwXnk",
        "outputId": "2ceacbd0-161b-4b1d-ed34-2f730333704f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/tieulyphidao/project_data_science/movieclassifier/movieclassifier\n"
          ]
        }
      ],
      "source": [
        "os.chdir('movieclassifier')\n",
        "\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Xc7MKCL6uPhy"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "import os\n",
        "\n",
        "conn = sqlite3.connect('reviews.sqlite')\n",
        "c = conn.cursor()\n",
        "c.execute('DROP TABLE IF EXISTS review_db')\n",
        "c.execute('CREATE TABLE review_db'\\\n",
        "          ' (review TEXT, sentiment INTEGER, date TEXT)')\n",
        "\n",
        "example1 = \"I love this movie\"\n",
        "c.execute(\"INSERT INTO review_db\"\\\n",
        "          \" (review, sentiment, date) VALUES\"\\\n",
        "          \" (?, ?, DATETIME('now'))\", (example1, 1))\n",
        "\n",
        "example2 = \"I disliked this movie\"\n",
        "c.execute(\"INSERT INTO review_db\"\\\n",
        "          \" (review, sentiment, date) VALUES\"\\\n",
        "          \" (?, ?, DATETIME('now'))\", (example2, 0))\n",
        "conn.commit()\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Te-80_MgxLz5",
        "outputId": "6059f60f-4cc5-421f-f1db-949a709b6dc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('I love this movie', 1, '2025-06-30 13:08:27'), ('I disliked this movie', 0, '2025-06-30 13:08:27')]\n"
          ]
        }
      ],
      "source": [
        "conn = sqlite3.connect('reviews.sqlite')\n",
        "c = conn.cursor()\n",
        "c.execute(\"SELECT * FROM review_db WHERE date BETWEEN '2017-01-01 00:00:00' AND DATETIME('now')\")\n",
        "results = c.fetchall()\n",
        "conn.close()\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "_16U2tQu64eN"
      },
      "outputs": [],
      "source": [
        "os.mkdir(os.path.join(os.getcwd(), '1st_flask_app_1'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "td-dTXxYyco9"
      },
      "outputs": [],
      "source": [
        "code = '''\n",
        "from flask import Flask, render_template\n",
        "\n",
        "app = Flask(__name__)\n",
        "@app.route('/')\n",
        "def index():\n",
        "  return render_template('first_app.html')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  app.run()\n",
        "'''\n",
        "with open(os.path.join(os.getcwd(), '1st_flask_app_1', 'app.py'), 'w') as f:\n",
        "  f.write(code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "RDaSH0ds6vXs"
      },
      "outputs": [],
      "source": [
        "os.mkdir(os.path.join(os.getcwd(), '1st_flask_app_1', 'templates'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "stTsuUwp7KnV"
      },
      "outputs": [],
      "source": [
        "code = '''\n",
        "<!doctype html>\n",
        "<html>\n",
        "  <head>\n",
        "    <title>First app</title>\n",
        "  </head>\n",
        "  <body>\n",
        "    <div>Hi, this is my first Flask web app!</div>\n",
        "  </body>\n",
        "</html>\n",
        "'''\n",
        "with open(os.path.join(os.getcwd(), '1st_flask_app_1', 'templates', 'first_app.html'), 'w') as f:\n",
        "  f.write(code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "yFR58nKE8Bn8"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.join(os.getcwd(), '1st_flask_app_1'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xKKqKgC9bb0"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, render_template, request\n",
        "from wtforms import Form, TextAreaField, validators\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "class HelloForm(Form):\n",
        "  sayhello = TextAreaField('', [validators.DataRequired()])\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "  form = HelloForm(request.form)\n",
        "  return render_template('first_app.html', form=form)\n",
        "\n",
        "@app.route('/hello', methods=['POST'])\n",
        "def hello():\n",
        "  form = HelloForm(request.form)\n",
        "  if request.method == 'POST' and form.validate():\n",
        "    name = request.form['sayhello']\n",
        "    return render_template('hello.html', name=name)\n",
        "  return render_template('first_app.html', form=form)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  app.run(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ds-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
